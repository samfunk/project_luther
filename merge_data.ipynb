{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Merge all data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook accumulates each data set and merges them on date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pickle\n",
    "from functools import reduce\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set pandas options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_columns', None)\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import MarketWatch articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickles = ['links', 'econ', 'fed', 'strong', 'soft']\n",
    "\n",
    "for p in pickles:\n",
    "    with open('/Users/samfunk/ds/metis/project_luther/' + p + '.pkl', 'rb') as f:\n",
    "        globals()[str(p)] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert article info into dataframe and format date and url columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_df(dictfile, colname):\n",
    "    '''\n",
    "    Make dataframes out of raw article dictionaries. Format dates, urls, and limit to relevant time horizon\n",
    "    ---\n",
    "    IN: dictfile = imported article dictionaries, colname = dataframe column name for merging\n",
    "    OUT: formatted dataframe\n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        dictlist = [x for x in dictfile.items()]\n",
    "    except:\n",
    "        dictlist = dictfile\n",
    "\n",
    "    df['article'] = [x[0].lower() for x in dictlist]\n",
    "    df['datetime'] = [x[1]['date'] for x in dictlist]\n",
    "    df['url'] = [x[1]['url'] for x in dictlist]\n",
    "    if colname != 'links':\n",
    "        df[colname] = 1\n",
    "    \n",
    "    regex = re.compile('[%s]' % re.escape(string.punctuation.replace(':', '')))\n",
    "    df['datetime'] = df['datetime'].apply(lambda x: regex.sub('', x))\n",
    "\n",
    "    df['time'] = df['datetime'].apply(lambda x: re.search(r'^(.+?\\s.+?)\\s', x)[1])\n",
    "    df['time_string'] = df['time'].apply(lambda x: datetime.strptime(x, '%I:%M %p').time())\n",
    "\n",
    "    df['date'] = df['datetime'].apply(lambda x: re.search(r'([A-Z].*)', x)[1])\n",
    "    df['date'] = df['date'].apply(lambda x: re.sub(r'([A-Za-z]{3})[a-z]*', r'\\1', x))\n",
    "    df['date'] = df['date'].apply(lambda x: datetime.strptime(x, '%b %d %Y'))\n",
    "    df['date_string'] = df['date'].apply(lambda x: x.date())\n",
    "\n",
    "    df['datetime'] = df.apply(lambda x: datetime.combine(x['date_string'], x['time_string']), axis=1)\n",
    "\n",
    "    df['month'] = df['datetime'].apply(lambda x: x.month)\n",
    "    df['day'] = df['datetime'].apply(lambda x: x.weekday())\n",
    "\n",
    "    df['url'] = df['url'].apply(lambda x: 'http://marketwatch.com' + x if 'http' not in x else x)\n",
    "    \n",
    "    df = df.sort_values('datetime')\n",
    "    \n",
    "    df = df[(df['month'] > 5) & (df['month'] < 10)]\n",
    "    df = df[df['day'] < 5]\n",
    "\n",
    "    return df.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge (concatenate) all dataframes into `master`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_links = to_df(links, 'links')\n",
    "df_econ = to_df(econ, 'econ')\n",
    "df_fed = to_df(fed, 'fed')\n",
    "df_strong = to_df(strong, 'strong')\n",
    "df_soft = to_df(soft, 'soft')\n",
    "data = [df_links, df_econ, df_fed, df_strong, df_soft]\n",
    "\n",
    "master = pd.concat(data, ignore_index=True)\n",
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format `master` and add additional columns of variable transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = Counter(master.datetime)\n",
    "dups = [n for n in c if c[n] > 1]\n",
    "mask = master.datetime.isin(dups)\n",
    "result = master.loc[(~mask) | ((mask) & (master.econ > 0)) | ((mask) & (master.fed > 0)) | ((mask) & (master.strong > 0)) | ((mask) & (master.soft > 0)), :]\n",
    "\n",
    "master = result.drop_duplicates()\n",
    "master = master.fillna(0)\n",
    "master = master[master['date'] != '2016-07-08']\n",
    "\n",
    "count = master.groupby('date')['article'].count().reset_index().set_index('date')\n",
    "sums = master.groupby('date')['econ', 'fed', 'strong', 'soft'].sum().reset_index().set_index('date')\n",
    "master = sums.join(count, how='left')\n",
    "\n",
    "master['econ_day'] = master['econ'] / master['article']\n",
    "master['strong_day'] = master['strong'] / master['article']\n",
    "master['strong_soft'] = master['strong'] + master['soft']\n",
    "master['ss_day'] = master['strong_soft'] / master['article']\n",
    "\n",
    "master['strong_econ'] = master['strong'] / master['econ']\n",
    "master['ss_econ'] = master['strong_soft'] / master['econ']\n",
    "\n",
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and merge Fed calendar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/samfunk/ds/metis/project_luther/calendar.pkl', 'rb') as f:\n",
    "    calendar = pickle.load(f)\n",
    "\n",
    "calendar = calendar.groupby(calendar.index).first().reset_index().set_index('date')\n",
    "\n",
    "master = master.join(calendar, how='left')\n",
    "master = master.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and merge Google Trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/samfunk/ds/metis/project_luther/trends.pkl', 'rb') as f:\n",
    "    trends = pickle.load(f)\n",
    "    \n",
    "trends.rename(columns={'lag1': 'trend_lag1', 'lag2': 'trend_lag2', 'federal reserve': 'federal_reserve', 'unemployment rate': 'unemployment'}, inplace=True)\n",
    "\n",
    "master = master.join(trends, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in and merge SPX data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spx = pd.read_csv('/Users/samfunk/Downloads/GSPC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spx['Date'] = spx['Date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d'))\n",
    "spx = spx.sort_values(by='Date').set_index('Date')\n",
    "\n",
    "spx = spx['06-01-2017':'10-02-2017']\n",
    "\n",
    "spx['lag1'] = spx['Close'].diff()\n",
    "spx['perc_change'] = spx['Close'].diff() / spx['Close'].shift()\n",
    "\n",
    "spx = spx[['Close', 'lag1', 'perc_change']]\n",
    "\n",
    "master = master.join(spx, how='left')\n",
    "master = master[np.isfinite(master.lag1)]\n",
    "\n",
    "master.rename(columns={'lag1': 'spx_lag', 'Close': 'close'}, inplace=True)\n",
    "master['abs_lag'] = master['spx_lag'].apply(lambda x: abs(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "master.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save `master` data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/samfunk/ds/metis/project_luther/master.pkl', 'wb') as f:\n",
    "    pickle.dump(master, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
